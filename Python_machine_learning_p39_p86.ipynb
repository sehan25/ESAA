{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Python machine learning p39-p86.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMF/2aZ7FGxBEXg73OY0Zp+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sehan25/ESSA/blob/main/Python_machine_learning_p39_p86.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **04. 데이터 핸들링 - 판다스**\n",
        "\n",
        "---\n",
        "* 판다스는 파이썬에서 데이터 처리를 위해 존재하는 가장 인기 있는 라이브러리이다.\n",
        "* 행과 열로 이뤄진 2차원 데이터를 효율적으로 가공/처리할 수 있는 다양하고 훌륭한 기능을 제공한다.\n",
        "* 많은 부분이 넘파이 기반으로 작성됐는데, 넘파이보다 훨씬 유연하고 편리하게 데이터 핸들링을 가능하게 해준다.\n",
        "* 파이썬의 리스트, 컬렉션, 넘파이 등의 내부 데이터뿐만 아니라 CSV 등의 파일을 쉽게 DataFrame으로 변경해 데이터의 가공/분석을 편리하게 수행할 수 있게 만든다.\n",
        "* 판다스의 핵심 객체는 **DataFrame**이다. 다른 중요 객체인 Index와 Series를 이해하는 것도 중요하다.\n",
        "    * **DataFrame**: 여러 개의 행과 열로 이뤄진 2차원 데이터를 담는 데이터 구조체\n",
        "    * Index: RDBMS의 PK처럼 개별 데이터를 고유하게 식별하는 Key 값\n",
        "    * Series와 DataFrame의 가장 큰 차이는 Series는 칼럼이 하나뿐인 데이터 구조체, DataFrame은 칼럼이 여러 개인 데이터 구조체\n",
        "\n"
      ],
      "metadata": {
        "id": "HmuhtuaF_RMz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> ### 판다스 시작 - 파일을 DataFrame으로 로딩, 기본 API\n",
        "> ---\n",
        "\n",
        "```\n",
        "import pandas as pd\n",
        "```\n",
        "* 판다스는 다양한 포맷으로 된 파일을 DataFrame으로 로딩할 수 있는 편리한 API를 제공한다.  \n",
        "ex) `read_csv(), read_table(), read_fwf()`\n",
        "    * **`read_csv()`**: CSV(칼럼을 ','로 구분한 파일 포맷) 파일 포맷 변환을 위한 API  \n",
        "        * 인자인 sep에 해당 구분 문자를 할당함으로써 어떤 필드 구분 문자 기반의 파일 포맷도 DataFrame으로 변환 가능\n",
        "        * 인자인 filepath에 로드하려는 데이터 파일의 경로를 포함한 파일명을 입력, 파일명만 입력되면 파이썬 실행 파일이 있는 디렉터리와 동일한 디렉터리에 있는 파일명을 로딩\n",
        "    * `read_table()`: 디폴트 필드 구분 문자(Delimeter)가 탭('\\t') 문자\n",
        "    * `read_fwf()`: Fixed Width, 즉 고정 길이 기반의 칼럼 포맷을 DataFrame으로 로딩하기 위한 API\n"
      ],
      "metadata": {
        "id": "eknAg1mHkbgj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_CJeWpAm-vxH"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "titanic_df = pd.read_csv('/content/drive/MyDrive/ESAA/data/titanic_train.csv')\n",
        "print('titanic 변수 type:', type(titanic_df))\n",
        "titanic_df"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **`head()`**: DataFrame의 맨 앞에 있는 N개의 로우를 반환한다. (Default는 5개)\n",
        "* **`shape`**: DataFrame의 행과 열을 튜플 형태로 반환한다.\n",
        "* **`info()`**: 총 데이터 건수와 데이터 타입, Null 건수를 알 수 있다.\n",
        "* **`describe()`**: 칼럼별 숫자형(int, float 등) 데이터값의 Not Null인 데이터 건수, n-percentile 분포도, 평균값, 최댓값, 최솟값을 나타낸다. (object 타입의 칼럼은 출력에서 제외)\n",
        "* **`value_counts()`**: 지정된 칼럼의 데이터값 건수를 반환한다. 데이터의 분포도를 확인하는 데 매우 유용한 함수이다.\n",
        "    * 많은 건수 순서로 정렬되어 값을 반환\n",
        "    * Series 객체에서만 정의되어 있으며, 반환하는 데이터 타입 역시 Series 객체(왼쪽이 인덱스값, 오른쪽이 데이터값)\n",
        "    * 고유 칼럼 값을 식별자로 사용 가능"
      ],
      "metadata": {
        "id": "ZPnvp3Fwnxg6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "titanic_df.head(3)"
      ],
      "metadata": {
        "id": "H6ZGn_ruGb7I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('DataFrame 크기: ', titanic_df.shape)"
      ],
      "metadata": {
        "id": "JsSp5FaQG7WP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "titanic_df.info()"
      ],
      "metadata": {
        "id": "ssQQYOO0HBvd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "titanic_df.describe()"
      ],
      "metadata": {
        "id": "qYGe8xqdKVvB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "titanic_pclass = titanic_df['Pclass']\n",
        "print(type(titanic_pclass))"
      ],
      "metadata": {
        "id": "5opWEGEoLPzI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "titanic_pclass.head()"
      ],
      "metadata": {
        "id": "yj-fuvq_LZi4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "value_counts = titanic_df['Pclass'].value_counts()\n",
        "print(type(value_counts))\n",
        "print(value_counts)"
      ],
      "metadata": {
        "id": "UG6U-SpGLda5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> ### DataFrame과 리스트, 딕셔너리, 넘파이 ndarray 상호 변환\n",
        "> ---\n",
        "\n",
        "기본적으로 DataFrame은 파이썬의 리스트, 딕셔너리 그리고 넘파이 ndarray 등 다양한 데이터로부터 생성될 수 있고, 반대로 파이썬의 리스트, 딕셔너리, 넘파이 ndarray 등으로 변환될 수 있다.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "UVnloe8Ps4kT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> #### *넘파이 ndarray, 리스트, 딕셔너리를 DataFrame으로 변환하기*\n",
        "\n",
        "* 1차원 형태의 리스트와 넘파이 ndarray부터 DataFrame으로 변환"
      ],
      "metadata": {
        "id": "d1jWdsPytkWP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "col_name1 = ['col']\n",
        "list1 = [1, 2, 3]\n",
        "array1 = np.array(list1)\n",
        "print('array1 shape:', array1.shape)\n",
        "\n",
        "#리스트를 이용해 DataFrame 생성.\n",
        "df_list1 = pd.DataFrame(list1, columns=col_name1)\n",
        "print('1차원 리스트로 만든 DataFrame:\\n', df_list1)\n",
        "\n",
        "#넘파이 ndarray를 이용해 DataFrame 생성.\n",
        "df_array1 = pd.DataFrame(array1, columns=col_name1)\n",
        "print('1차원 ndarray로 만든 DataFrame:\\n', df_array1)"
      ],
      "metadata": {
        "id": "sRcK8FuuLtcS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#3개의 칼럼명이 필요함.\n",
        "col_name2 = ['col1', 'col2', 'col3']\n",
        "\n",
        "#2행*3열 형태의 리스트와 ndarray 생성한 뒤 이를 DataFrame으로 변환.\n",
        "list2 = [[1, 2, 3],\n",
        "         [11, 12, 13]]\n",
        "array2 = np.array(list2)\n",
        "print('array2 shape:', array2.shape)\n",
        "\n",
        "df_list2 = pd.DataFrame(list2, columns=col_name2)\n",
        "print('2차원 리스트로 만든 DataFrame:\\n', df_list2)\n",
        "df_array2 = pd.DataFrame(array2, columns=col_name2)\n",
        "print('2차원 ndarray로 만든 DataFrame:\\n', df_array2)"
      ],
      "metadata": {
        "id": "4DjWhnFFNd7Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 딕셔너리를 DataFrame으로 변환\n",
        "    * 키의 경우는 문자열, 값의 경우 리스트(또는 ndarray) 형태로 딕셔너리 구성"
      ],
      "metadata": {
        "id": "fRnI66uU-R5a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Key는 문자열 칼럼명으로 매핑, Value는 리스트 형(또는 ndarray) 칼럼 데이터로 매핑\n",
        "dict = {'col1':[1,11], 'col2':[2,22],'col3':[3,33]}\n",
        "df_dict = pd.DataFrame(dict)\n",
        "print('딕셔너리로 만든 DataFrame:\\n', df_dict)"
      ],
      "metadata": {
        "id": "Kmfy60a2QewQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> #### *DataFrame을 넘파이 ndarray, 리스트, 딕셔너리로 변환하기*\n",
        "\n",
        "* 넘파이 ndarray로 변환: DataFrame 객체의 values 이용\n",
        "* 리스트로의 변환: values로 얻은 ndarray에 `tolist()`를 호출\n",
        "* 딕셔너리로의 변환: DataFrame 객체의 `to_dict()` 메서드 호출, 인자로 '`list`'를 입력하면 딕셔너리의 값이 리스트형으로 반환 "
      ],
      "metadata": {
        "id": "njGBQ_P7Wb6B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DataFrame을 ndarray로 변환\n",
        "array3 = df_dict.values\n",
        "print('df_dict.values 타입:', type(array3), 'df_dict.values shape:', array3.shape)\n",
        "print(array3)"
      ],
      "metadata": {
        "id": "N38rryPnQ5vH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DataFrame을 리스트로 변환\n",
        "list3 = df_dict.values.tolist()\n",
        "print('df_dict.values.tolist() 타입:', type(list3))\n",
        "print(list3)\n",
        "\n",
        "# DataFrame을 딕셔너리로 변환\n",
        "dict3 = df_dict.to_dict('list')\n",
        "print('\\n df_dict.to_dict() 타입:', type(dict3))\n",
        "print(dict3)"
      ],
      "metadata": {
        "id": "bv3NkM65RLfZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> ### DataFrame의 칼럼 데이터 세트 생성과 수정\n",
        "> ---\n",
        "\n",
        "* 생성: DataFrame `[ ]` 내에 **새로운 칼럼명을 입력하고 값을 할당**\n",
        "* 수정: 업데이트를 원하는 칼럼 Series를 DataFrame `[ ]` 내에 칼럼 명으로 입력하고 값을 할당"
      ],
      "metadata": {
        "id": "hOgO78iAAQP3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "titanic_df['Age_0'] = 0\n",
        "titanic_df.head(3)"
      ],
      "metadata": {
        "id": "Hx0-3gCLScdZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "titanic_df['Age_by_10'] = titanic_df['Age']*10\n",
        "titanic_df['Family_No'] = titanic_df['SibSp'] + titanic_df['Parch'] + 1\n",
        "titanic_df.head(3)"
      ],
      "metadata": {
        "id": "1-3T1PzjSmXO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "titanic_df['Age_by_10'] = titanic_df['Age_by_10'] + 100\n",
        "titanic_df.head(3)"
      ],
      "metadata": {
        "id": "Iurxr9UdS_g7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> ### DataFrame 데이터 삭제\n",
        "> ---\n",
        "\n",
        "* **`drop()`** 메서드의 원형\n",
        "```\n",
        "DataFrame.drop(labels=None, axis=0, index=None, columns=None, level=None, inplace=False, errors='raise')\n",
        "```\n",
        "    * **axis**: **`axis=1`**을 입력하면 **칼럼 방향 축 방향**으로 / **`axis=0`**을 입력하면 **로우 축 방향으로 드롭**을 수행\n",
        "    * **inplace**: **`inplace=False`**이면 자기 자신의 DataFrame의 데이터는 삭제하지 않으며, 삭제된 결과 DataFrame을 반환 / **`inplace=True`**로 설정하면 자신의 DataFrame의 데이터 삭제, 반환 값이 None(아무 값도 아님)이 되어 반환 값을 다시 자신의 DataFrame 객체로 할당 불가능"
      ],
      "metadata": {
        "id": "lCXk-oMVBGTt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "titanic_drop_df = titanic_df.drop('Age_0', axis=1)\n",
        "titanic_drop_df.head(3)"
      ],
      "metadata": {
        "id": "IuDbiGiMTqgH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drop_result = titanic_df.drop(['Age_0', 'Age_by_10', 'Family_No'], axis=1, inplace=True)\n",
        "print('inplace=True 로 drop 후 반환된 값:', drop_result)\n",
        "titanic_df.head(3)"
      ],
      "metadata": {
        "id": "0ADl_x0rWwIg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.width', 1000)\n",
        "pd.set_option('display.max_colwidth', 15)\n",
        "print('#### before axis 0 drop ####')\n",
        "print(titanic_df.head(3))\n",
        "\n",
        "titanic_df.drop([0, 1, 2], axis=0, inplace=True)\n",
        "print('#### after axis 0 drop ####')\n",
        "print(titanic_df.head(3))"
      ],
      "metadata": {
        "id": "9p0Wc0gIXA0q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> ### Index 객체\n",
        "> ---\n",
        "\n",
        ": RDBMS의 PK(Primary Key)와 유사하게 DataFrame, Series의 레코드를 고유하게 식별하는 객체"
      ],
      "metadata": {
        "id": "bJHR-eekXsRw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 원본 파일 다시 로딩\n",
        "titanic_df = pd.read_csv('/content/drive/MyDrive/ESAA/data/titanic_train.csv')"
      ],
      "metadata": {
        "id": "oRydvliMXiC-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Index 객체 추출\n",
        "indexes = titanic_df.index\n",
        "print(indexes)\n",
        "\n",
        "# Index 객체를 실제 값 array로 변환\n",
        "print('Index 객체 array값:\\n', indexes.values)"
      ],
      "metadata": {
        "id": "8x5qvTa0ZyDF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Index 객체는 식별성 데이터를 1차원 array로 가져 ndarray와 유사하게 단일 값 반환 및 슬라이싱도 가능"
      ],
      "metadata": {
        "id": "sA3608DwbHMg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(indexes.values))\n",
        "print(indexes.values.shape)\n",
        "print(indexes[:5].values)\n",
        "print(indexes.values[:5])\n",
        "print(indexes[6])"
      ],
      "metadata": {
        "id": "2RxSWNIkZ4Hr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 한 번 만들어진 DataFrame 및 Series의 Index 객체는 **함부로 변경 불가능**"
      ],
      "metadata": {
        "id": "z-TA4TXcbJGC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "indexes[0]=5"
      ],
      "metadata": {
        "id": "5CWHH6n7aihz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Series 객체는 Index 객체를 포함하지만 Series 객체에 연산 함수를 적용할 때 Index는 **연산에서 제외** (오직 식별용)"
      ],
      "metadata": {
        "id": "PyqUIgXqatr1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "series_fair = titanic_df['Fare']\n",
        "print('Fair Series max 값:', series_fair.max())\n",
        "print('Fair Series sum 값:', series_fair.sum())\n",
        "print('sum() Fair Series:', sum(series_fair))\n",
        "print('Fair Series + 3:\\n', (series_fair + 3).head(3))"
      ],
      "metadata": {
        "id": "U7gMm443akhD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **`reset_index()`** : **새롭게 인덱스를 연속 숫자 형으로 할당**하며 기존 **인덱스는 'index'라는 새로운 칼럼 명으로 추가**\n",
        "    * 인덱스가 연속된 int 숫자형 데이터가 아닐 경우에 다시 이를 연속 int 숫자형 데이터로 만들 때 주로 사용\n",
        "    * parameter 중 **`drop=True`**로 설정하면 기존 인덱스는 새로운 칼럼으로 추가되지 않고 **삭제(drop)**"
      ],
      "metadata": {
        "id": "8tq8-6Y2blrR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "titanic_reset_df = titanic_df.reset_index(inplace=False)\n",
        "titanic_reset_df.head(3)"
      ],
      "metadata": {
        "id": "p_UL5SoQbeCw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('### before reset_index ###')\n",
        "value_counts = titanic_df['Pclass'].value_counts()\n",
        "print(value_counts)\n",
        "print('value_counts 객체 변수 타입:', type(value_counts))\n",
        "\n",
        "new_value_counts = value_counts.reset_index(inplace=False)\n",
        "print('### After reset_index ###')\n",
        "print(new_value_counts)\n",
        "print('new_value_counts 객체 변수 타입:', type(new_value_counts))"
      ],
      "metadata": {
        "id": "k_069WP5cPy5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> ### 데이터 셀렉션 및 필터링\n",
        "> ---\n",
        "\n",
        "넘파이의 경우 '`[ ]`' 연산자 내 단일 값 추출, 슬라이싱, 팬시 인덱싱, 불린 인덱싱을 통해 데이터를 추출했는데, 판다스의 경우 `ix[ ], iloc[ ], loc[ ]` 연산자를 통해 동일한 작업 수행한다."
      ],
      "metadata": {
        "id": "1cmzYC6RdMNR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> #### *DataFrame의 `[ ]` 연산자*\n",
        "\n",
        "* DataFrame 바로 뒤에 있는 '`[ ]`' 안에 들어갈 수 있는 것은 칼럼 명 문자(또는 칼럼 명의 리스트 객체), 또는 인덱스로 변환 가능한 표현식  \n",
        " *cf)* 칼럼만 지정할 수 있는 '칼럼 지정 연산자'로 이해하는 게 혼돈을 막는 좋은 방법\n",
        "\n",
        " * DataFrame 바로 뒤의 `[ ]` 연산자는 넘파이의 `[ ]`나 Series의 `[ ]` 와 다름\n",
        " * DataFrame 바로 뒤의 `[ ]` 내 입력 값은 칼럼명(또는 칼럼의 리스트)을 지정해 칼럼 지정 연산에 사용하거나 불린 인덱스 용도로만 사용해야 함\n",
        " * 슬라이싱 연산으로 데이터를 추출하는 방법은 사용하지 않는 게 좋음"
      ],
      "metadata": {
        "id": "bL2ykcIreTo4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('단일 칼럼 데이터 추출:\\n', titanic_df['Pclass'].head(3))\n",
        "print('\\n여러 칼럼의 데이터 추출:\\n', titanic_df[ ['Survived', 'Pclass'] ].head(3))\n",
        "print('[ ] 안에 숫자 index는 KeyError 오류 발생:\\n', titanic_df[0])"
      ],
      "metadata": {
        "id": "OgWYW_76cxeg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "titanic_df[ 0:2 ]"
      ],
      "metadata": {
        "id": "nuj9UJ2Ofvv-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "titanic_df [ titanic_df['Pclass'] == 3 ].head(3)"
      ],
      "metadata": {
        "id": "g_EE0rrJgVJQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> #### *DataFrame `ix[ ]` 연산자*\n",
        "\n",
        "* `ix[ ]`: 행에 해당하는 위치 지정은 DataFrame의 인덱스값을 입력, 열 위치 지정은 칼럼 명뿐만 아니라 칼럼의 위치 값 지정도 가능\n",
        "* 현재 판다스에서 사라지게 되었다."
      ],
      "metadata": {
        "id": "kE6gNw2ohO9u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('칼럼 위치 기반 인덱싱 데이터 추출:', titanic_df.ix[0, 2])\n",
        "print('칼럼 명 기반 인덱싱 데이터 추출:', titanic_df.ix[0, 'Pclass'])"
      ],
      "metadata": {
        "id": "VIwnNKwLghch"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = {'Name': ['Chulmin', 'Eunkyung', 'Jinwoong', 'Soobeom'],\n",
        "        'Year': [2011, 2016, 2015, 2015],\n",
        "        'Gender': ['Male', 'Female', 'Male', 'Male']\n",
        "        }\n",
        "data_df = pd.DataFrame(data, index=['one', 'two', 'three', 'four'])\n",
        "data_df"
      ],
      "metadata": {
        "id": "Rg9lP7pVo5A7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> #### *명칭 기반 인덱싱과 위치 기반 인덱싱의 구분*\n",
        "\n",
        "* 명칭(Label) 기반 인덱싱: **칼럼의 명칭을 기반으로 열 위치를 지정**하는 방식\n",
        "* 위치(Position) 기반 인덱싱: 0을 출발점으로 하는 가로축, 세로축 좌표 기반의 **행과 열 위치를 기반으로 데이터를 지정**하는 방식\n",
        " "
      ],
      "metadata": {
        "id": "hEe090P5B9n_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# data_df를 reset_index()로 새로운 숫자형 인덱스를 생성\n",
        "data_df_reset = data_df.reset_index()\n",
        "data_df_reset = data_df.rename(columns={'index':'old_index'})\n",
        "\n",
        "# 인덱스값에 1을 더해서 1부터 시작하는 새로운 인덱스값 생성\n",
        "data_df_reset.index = data_df_reset.index+1\n",
        "data_df_reset"
      ],
      "metadata": {
        "id": "85vygNgQpYA_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> #### *DataFrame `iloc[ ]` 연산자*\n",
        "\n",
        "* **`iloc[ ]`**: **위치 기반 인덱싱만 가능**하기 때문에 **형과 열 값으로 integer 또는 integer형의 슬라이싱, 팬시 리스트 값을 입력**해 원하는 데이터 반환"
      ],
      "metadata": {
        "id": "1YcxjPpszqJp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_df.iloc[0, 0]"
      ],
      "metadata": {
        "id": "W3kg9D1Cp0Tg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 다음 코드는 오류를 발생합니다.\n",
        "data_df.iloc[0, 'Name']"
      ],
      "metadata": {
        "id": "k8ZA72mHqU07"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 다음 코드는 오류를 발생합니다.\n",
        "data_df.iloc['one', 0]"
      ],
      "metadata": {
        "id": "Xb8BUbgjC8wZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> #### *DataFrame `loc[ ]` 연산자*\n",
        "\n",
        "* **`loc[ ]`**: **명칭 기반**으로 데이터를 추출, **행 위치에는 DataFrame index 값을, 그리고 열 위치에는 칼럼 명을 입력**해 원하는 데이터 반환\n",
        "    * `loc[ ]`에 **슬라이싱 기호**를 적용하면 종료 값-1이 아니라 **종료 값까지 포함**하는 것을 의미"
      ],
      "metadata": {
        "id": "vhPhP_WoDDPa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_df.loc['one', 'Name']"
      ],
      "metadata": {
        "id": "yf_7qT2kqqO5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print('명칭 기반 ix slicing\\n', data_df.ix['one': 'two', 'Name'], '\\n')\n",
        "print('위치 기반 iloc slicing\\n', data_df.iloc[0:1, 0], '\\n')\n",
        "print('명칭 기반 loc slicing\\n', data_df.loc['one': 'two', 'Name'])"
      ],
      "metadata": {
        "id": "pycSOTzGqywt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> #### *불린 인덱싱*\n",
        "\n",
        "* 매우 편리한 데이터 필터링 방식이다.\n",
        "* `[ ], ix[ ], loc[ ]`에서 공통으로 지원하지만, `iloc[ ]`에서는 지원하지 않는다.\n",
        "* `[ ]` 내에 불린 인덱싱을 적용하면 반환되는 객체가 DataFrame이므로 원하는 칼럼 명만 별도로 추출할 수 있다.\n",
        "* `loc[ ]`를 이용해도 동일하게 적용할 수 있다.\n",
        "* 여러 개의 복합 조건도 결합해 적용할 수 있다.\n",
        "    1. and 조건일 때는 &\n",
        "    2. or 조건일 때는 |\n",
        "    3. Not 조건일 때는 ~\n",
        "\n"
      ],
      "metadata": {
        "id": "2pwH4focEOVe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "titanic_df = pd.read_csv('/content/drive/MyDrive/ESAA/data/titanic_train.csv')\n",
        "titanic_boolean = titanic_df[titanic_df['Age'] > 60]\n",
        "print(type(titanic_boolean))\n",
        "titanic_boolean.head(3)"
      ],
      "metadata": {
        "id": "9ciw9rsfsYNK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "titanic_df[titanic_df['Age'] > 60][['Name', 'Age']].head(3)"
      ],
      "metadata": {
        "id": "bmlpUwWtFkDh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "titanic_df.loc[titanic_df['Age'] > 60, ['Name', 'Age']].head(3)"
      ],
      "metadata": {
        "id": "INNaFP_NFzuY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "titanic_df[ (titanic_df['Age'] > 60) & (titanic_df['Pclass'] == 1) &\n",
        "            (titanic_df['Sex'] == 'female')]"
      ],
      "metadata": {
        "id": "tDtcvUzuF5v0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cond1 = titanic_df['Age'] > 60\n",
        "cond2 = titanic_df['Pclass'] == 1\n",
        "cond3 = titanic_df['Sex'] == 'female'\n",
        "titanic_df[ cond1 & cond2 & cond3 ]"
      ],
      "metadata": {
        "id": "thyQLKF5GFp3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> ### 정렬, Aggregation 함수, GroupBy 적용\n",
        "> ---"
      ],
      "metadata": {
        "id": "uY4ZarXIGaOz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> #### *DataFrame, Series의 정렬 - `sort_values()`*\n",
        "\n",
        "* 주요 입력 파라미터 `by, ascending, inplace`\n",
        "    * `by`로 특정 칼럼을 입력하면 **해당 칼럼으로 정렬**을 수행\n",
        "    * **`ascending=True`**로 설정하면 **오름차순**으로 정렬 / **`ascending=False`**로 설정하면 **내림차순**으로 정렬  \n",
        "    기본형: `asceding=True`\n",
        "    * **`inplace=False`**로 설정하면 **`sort()`를 호출한 DataFrame은 그대로 유지**하며 정렬된 DataFrame을 결과로 반환 / **`inplace=True`**로 설정하면 호출한 DataFrame의 정렬 **결과를 그대로 적용**  \n",
        "    기본형: `inplace=False`\n",
        "* 여러 개의 칼럼으로 정렬하려면 `by`에 리스트 형식으로 정렬하려는 칼럼을 입력한다."
      ],
      "metadata": {
        "id": "5rFqCWI-Gn90"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "titanic_sorted = titanic_df.sort_values(by=['Name'])\n",
        "titanic_sorted.head(3)"
      ],
      "metadata": {
        "id": "vFQI3l9aGTpF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "titanic_sorted = titanic_df.sort_values(by=['Pclass', 'Name'], ascending=False)\n",
        "titanic_sorted.head(3)"
      ],
      "metadata": {
        "id": "nfxkQlRxH8La"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> #### *Aggregation 함수 적용*\n",
        "\n",
        "* DataFrame에서 `min(), max(), sum(), count()`와 같은 aggregation 함수의 적용은 RDBMS SQL의 aggregation 함수 적용과 유사하다.\n",
        "* 모든 칼럼에 해당 aggregation을 적용한다.\n",
        "* 특정 칼럼에 aggregation 함수를 적용하기 위해서는 DataFrame에 대상 칼럼들만 추출해 적용하면 된다."
      ],
      "metadata": {
        "id": "vlWk2h7aIRue"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "titanic_df.count()"
      ],
      "metadata": {
        "id": "9Z2TBp9rIPQc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "titanic_df[['Age', 'Fare']].mean()"
      ],
      "metadata": {
        "id": "peAwqxsQI4vL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> #### *`groupby()` 적용*\n",
        "\n",
        "* 사용 시 입력 파라미터 **`by`에 칼럼을 입력하면 대상 칼럼으로 groupby**된다.\n",
        "* DataFrame에 `groupby()`를 호출하면 DataFrameGroupBy라는 또 다른 형태의 DataFrame을 반환한다.\n",
        "* DataFrame에 `groupby()`를 호출해 반환된 결과에 aggregation 함수를 호출하면 `groupby()` 대상 칼럼을 제외한 모든 칼럼에 해당 aggregation 함수를 적용한다.\n",
        "* 특정 칼럼만 aggregation 함수를 적용하려면 `groupby()`로 반환된 DataFrameGroupBy 객체에 **해당 칼럼을 필터링한 뒤 aggregation 함수를 적용**한다.\n",
        "* 하나의 칼럼에 서로 다른 aggregation 함수를 적용할 경우>  \n",
        "적용하려는 여러 개의 aggreagation 함수명을 DataFrameGroupBy 객체의 `agg()` 내에 리스트 형태의 인자로 입력해서 사용한다.\n",
        "* 여러 개의 칼럼이 서로 다른 aggregation 함수를 적용할 경우>  \n",
        "`agg()` 내에 입력 값으로 딕셔너리 형태로 aggregation이 적용될 칼럼들과 aggregation 함수를 입력.\n"
      ],
      "metadata": {
        "id": "g6xAw9OBJCKS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "titanic_groupby = titanic_df.groupby(by='Pclass')\n",
        "print(type(titanic_groupby))"
      ],
      "metadata": {
        "id": "1qGdM9k3I8my"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "titanic_groupby = titanic_df.groupby('Pclass').count()\n",
        "titanic_groupby"
      ],
      "metadata": {
        "id": "5ty6LfjFMEYv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "titanic_groupby = titanic_df.groupby('Pclass')[['PassengerId', 'Survived']].count()\n",
        "titanic_groupby"
      ],
      "metadata": {
        "id": "RthjtIeaMLXh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "titanic_df.groupby('Pclass')['Age'].agg([max, min])"
      ],
      "metadata": {
        "id": "-I2SfR5zMW21"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agg_format = {'Age':'max', 'SibSp':'sum', 'Fare':'mean'}\n",
        "titanic_df.groupby('Pclass').agg(agg_format)"
      ],
      "metadata": {
        "id": "YZQI6_3LMdYd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> ### 결손 데이터 처리하기\n",
        "> ---\n",
        "\n",
        "**결손 데이터**: 칼럼에 값이 없는, 즉 **NULL**인 경우를 의미하며, 이를 넘파이의 **NaN으로 표시**\n",
        "* 기본적으로 머신러닝 알고리즘은 NaN 값을 처리하지 않으므로 이 값을 다른 값으로 대체해야 한다.\n",
        "* NaN 값은 평균, 총합 등의 함수 연산 시 제외된다."
      ],
      "metadata": {
        "id": "cGBjvpzxMrKo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> #### *`isna()`로 결손 데이터 여부 확인*\n",
        "\n",
        "* **`isna()`**: 모든 칼럼의 값이 **NaN인지 아닌지를 True나 False로** 알려준다.\n",
        "* **결손 데이터의 개수**는 **`isna()` 결과에 `sum()` 함수를 추가해 구할 수** 있다.  \n",
        "`sum()`을 호출 시 True는 내부적으로 숫자 1로, False는 숫자 0으로 변환된다."
      ],
      "metadata": {
        "id": "kR1uvLzeNKrG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "titanic_df.isna().head(3)"
      ],
      "metadata": {
        "id": "MqAmjqxSMoLd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "titanic_df.isna().sum()"
      ],
      "metadata": {
        "id": "MpyO1qq2N95N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> #### *`fillna()`로 결손 데이터 대체하기*\n",
        "\n",
        "* **`fillna()`**: **결손 데이터를 다른 값으로 대체**할 수 있다.\n",
        "* 실제 데이터 세트 값을 변경하려면 `fillna()`를 이용해 반환 값을 다시 받거나 inplace=True 파라미터를 `fillna()`에 추가해야 한다."
      ],
      "metadata": {
        "id": "LhxlequNOB3Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "titanic_df['Cabin'] = titanic_df['Cabin'].fillna('C000')\n",
        "titanic_df.head(3)"
      ],
      "metadata": {
        "id": "-D0W76kVO512"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "titanic_df['Age'] = titanic_df['Age'].fillna(titanic_df['Age'].mean())\n",
        "titanic_df['Embarked'] = titanic_df['Embarked'].fillna('S')\n",
        "titanic_df.isna().sum()"
      ],
      "metadata": {
        "id": "6UkUMESpN_6_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> ### apply lambda 식으로 데이터 가공\n",
        "> ---\n",
        "\n",
        "판다스는 apply 함수에 lambda 식을 결합해 DataFrame이나 Series의 레코드별로 데이터를 가공하는 기능을 제공한다.\n",
        "* **lambda 식**: 함수의 선언과 함수 내의 처리를 한 줄의 식으로 쉽게 변환하는 식\n",
        "    * 파이썬에서 함수형 프로그래밍(functional programming)을 지원하기 위해 만들어짐\n",
        "    * ':'로 입력 입자와 반환될 입력 인자의 계산식을 분리 ex) lambda x : x ** 2\n",
        "        * **':'의 왼쪽에 있는 x는 입력인자**를 가리키며, **오른쪽은 입력 인자의 계산식**으로 반환 값을 의미\n",
        "    * 여러 개의 값을 입력 인자로 사용해야 할 경우, `map()` 함수를 결합해서 사용"
      ],
      "metadata": {
        "id": "-yk_iyhAPFxW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_square(a):\n",
        "    return a**2\n",
        "\n",
        "print('3의 제곱은:', get_square(3))"
      ],
      "metadata": {
        "id": "YEQPQNA7OtHG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lambda_square = lambda x : x ** 2\n",
        "print('3의 제곱은:', lambda_square(3))"
      ],
      "metadata": {
        "id": "w3cca6NTQgm8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = [1, 2, 3]\n",
        "squares = map(lambda x : x**2, a)\n",
        "list(squares)"
      ],
      "metadata": {
        "id": "yW6Xm2lzQocW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 판다스 DataFrame의 lambda 식은 파이썬의 lambda 식을 그대로 적용한 것이다.\n",
        "    * if절의 경우) lambda 식 '`:`' 기호의 오른편에 반환 값이 있어야 하기 때문에 **if 식보다 반환 값을 먼저 기술**해야 함, else의 경우는 **else 식이 먼저 반환 값이 나중에** 오면 됨\n",
        "    * **if, else만 지원**하고 if, else if, else와 같이 else if는 지원하지 않음 -> else if를 이용하기 위해서는 else 절을 `()`로 내표해 `()` 내에서 다시 if else 적용해 사용\n",
        "    * else if가 많이 나와야 하는 경우나 switch case문의 경우) 아예 별도의 함수를 만드는 게 더 나음"
      ],
      "metadata": {
        "id": "rxzun9XfQ1bJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "titanic_df['Name_len'] = titanic_df['Name'].apply(lambda x : len(x))\n",
        "titanic_df[['Name', 'Name_len']].head(3)"
      ],
      "metadata": {
        "id": "4IXcz6-SQzCo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "titanic_df['Child_Adult'] = titanic_df['Age'].apply(lambda x : 'Child' if x <=15 else 'Adult')\n",
        "titanic_df[['Age', 'Child_Adult']].head(8)"
      ],
      "metadata": {
        "id": "pdbmiuf2RQ9p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "titanic_df['Age_cat'] = titanic_df['Age'].apply(lambda x : 'Child' if x<=15 else ('Adult' if x<=60\n",
        "                                                                                  else 'Elderly'))\n",
        "titanic_df['Age_cat'].value_counts()"
      ],
      "metadata": {
        "id": "vlf7h_xyReUW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 나이에 따라 세분화된 분류를 수행하는 함수 생성.\n",
        "def get_category(age):\n",
        "    cat = ''\n",
        "    if age <= 5: cat = 'Baby'\n",
        "    elif age <= 12: cat = 'Child'\n",
        "    elif age <= 18: cat = 'Teenager'\n",
        "    elif age <= 25: cat = 'Student'\n",
        "    elif age <= 35: cat = 'Young Adult'\n",
        "    elif age <= 60: cat = 'Adult'\n",
        "    else: cat = 'Elderly'\n",
        "\n",
        "    return cat\n",
        "\n",
        "# lambda 식에 위에서 생성한 get_category() 함수를 반환값으로 지정.\n",
        "# get_category(X)는 입력값으로 'Age' 칼럼 값을 받아서 해당하는 cat 반환\n",
        "titanic_df['Age_cat'] = titanic_df['Age'].apply(lambda x : get_category(x))\n",
        "titanic_df[['Age', 'Age_cat']].head()"
      ],
      "metadata": {
        "id": "d6hrVA0nTEqG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}